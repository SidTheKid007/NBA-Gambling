{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>HTWin</th>\n",
       "      <th>HTLoss</th>\n",
       "      <th>HT%</th>\n",
       "      <th>ATWin</th>\n",
       "      <th>ATLoss</th>\n",
       "      <th>AT%</th>\n",
       "      <th>Date</th>\n",
       "      <th>WinMargin</th>\n",
       "      <th>TopLine</th>\n",
       "      <th>TLCompany</th>\n",
       "      <th>BotLine</th>\n",
       "      <th>BLCompany</th>\n",
       "      <th>Average</th>\n",
       "      <th>NumComps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SAC</td>\n",
       "      <td>UTA</td>\n",
       "      <td>11.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.216</td>\n",
       "      <td>29.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.569</td>\n",
       "      <td>2009-02-06</td>\n",
       "      <td>-4</td>\n",
       "      <td>-2</td>\n",
       "      <td>Pinnacle Sports</td>\n",
       "      <td>-3</td>\n",
       "      <td>Sportsbetting</td>\n",
       "      <td>-2.875</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>POR</td>\n",
       "      <td>UTA</td>\n",
       "      <td>29.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.630</td>\n",
       "      <td>26.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.542</td>\n",
       "      <td>2009-01-31</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>5Dimes</td>\n",
       "      <td>9</td>\n",
       "      <td>5Dimes</td>\n",
       "      <td>9.000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>MEM</td>\n",
       "      <td>UTA</td>\n",
       "      <td>11.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.282</td>\n",
       "      <td>24.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>2009-01-16</td>\n",
       "      <td>-10</td>\n",
       "      <td>-4</td>\n",
       "      <td>5Dimes</td>\n",
       "      <td>-4</td>\n",
       "      <td>5Dimes</td>\n",
       "      <td>-4.000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>UTA</td>\n",
       "      <td>IND</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.605</td>\n",
       "      <td>13.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.342</td>\n",
       "      <td>2009-01-12</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>Bovada</td>\n",
       "      <td>9</td>\n",
       "      <td>Sportsbetting</td>\n",
       "      <td>9.250</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>HOU</td>\n",
       "      <td>UTA</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.645</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.563</td>\n",
       "      <td>2008-12-27</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5Dimes</td>\n",
       "      <td>9</td>\n",
       "      <td>5Dimes</td>\n",
       "      <td>9.000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 HomeTeam AwayTeam  HTWin  HTLoss    HT%  ATWin  ATLoss    AT%  \\\n",
       "0           0      SAC      UTA   11.0    40.0  0.216   29.0    22.0  0.569   \n",
       "1           1      POR      UTA   29.0    17.0  0.630   26.0    22.0  0.542   \n",
       "2           2      MEM      UTA   11.0    28.0  0.282   24.0    16.0  0.600   \n",
       "3           3      UTA      IND   23.0    15.0  0.605   13.0    25.0  0.342   \n",
       "4           4      HOU      UTA   20.0    11.0  0.645   18.0    14.0  0.563   \n",
       "\n",
       "         Date  WinMargin  TopLine        TLCompany  BotLine      BLCompany  \\\n",
       "0  2009-02-06         -4       -2  Pinnacle Sports       -3  Sportsbetting   \n",
       "1  2009-01-31         14        9           5Dimes        9         5Dimes   \n",
       "2  2009-01-16        -10       -4           5Dimes       -4         5Dimes   \n",
       "3  2009-01-12          7       10           Bovada        9  Sportsbetting   \n",
       "4  2008-12-27          5        9           5Dimes        9         5Dimes   \n",
       "\n",
       "   Average  NumComps  \n",
       "0   -2.875         8  \n",
       "1    9.000         8  \n",
       "2   -4.000         8  \n",
       "3    9.250         8  \n",
       "4    9.000         8  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt \n",
    "df = pd.read_csv('CombinedBettingData3.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HomeTeam', 'AwayTeam', 'HTWin', 'HTLoss', 'HT%', 'ATWin', 'ATLoss',\n",
       "       'AT%', 'Date', 'WinMargin', 'TopLine', 'TLCompany', 'BotLine',\n",
       "       'BLCompany', 'Average', 'NumComps'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "df = df.dropna()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>HTWin</th>\n",
       "      <th>HTLoss</th>\n",
       "      <th>HT%</th>\n",
       "      <th>ATWin</th>\n",
       "      <th>ATLoss</th>\n",
       "      <th>AT%</th>\n",
       "      <th>WinMargin</th>\n",
       "      <th>TopLine</th>\n",
       "      <th>TLCompany</th>\n",
       "      <th>BotLine</th>\n",
       "      <th>BLCompany</th>\n",
       "      <th>Average</th>\n",
       "      <th>NumComps</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MIN</td>\n",
       "      <td>SAC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>Pinnacle Sports</td>\n",
       "      <td>4</td>\n",
       "      <td>Bookmaker</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NJN</td>\n",
       "      <td>TOR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>Bookmaker</td>\n",
       "      <td>7</td>\n",
       "      <td>Bookmaker</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MEM</td>\n",
       "      <td>NYK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>Bovada</td>\n",
       "      <td>4</td>\n",
       "      <td>5Dimes</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORL</td>\n",
       "      <td>CHI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15</td>\n",
       "      <td>-1</td>\n",
       "      <td>Bookmaker</td>\n",
       "      <td>-2</td>\n",
       "      <td>Bovada</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CLE</td>\n",
       "      <td>WAS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>Bovada</td>\n",
       "      <td>6</td>\n",
       "      <td>Bovada</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HomeTeam AwayTeam  HTWin  HTLoss  HT%  ATWin  ATLoss  AT%  WinMargin  \\\n",
       "0      MIN      SAC    1.0     0.0  1.0    0.0     1.0  0.0          9   \n",
       "1      NJN      TOR    1.0     0.0  1.0    0.0     1.0  0.0         10   \n",
       "2      MEM      NYK    0.0     1.0  0.0    1.0     0.0  1.0         -1   \n",
       "3      ORL      CHI    1.0     0.0  1.0    1.0     1.0  0.5         15   \n",
       "4      CLE      WAS    1.0     0.0  1.0    0.0     1.0  0.0          3   \n",
       "\n",
       "   TopLine        TLCompany  BotLine  BLCompany  Average  NumComps  Year  \\\n",
       "0        5  Pinnacle Sports        4  Bookmaker     4.75         4  2006   \n",
       "1        7        Bookmaker        7  Bookmaker     7.00         4  2006   \n",
       "2        5           Bovada        4     5Dimes     4.75         4  2006   \n",
       "3       -1        Bookmaker       -2     Bovada    -1.25         4  2006   \n",
       "4        6           Bovada        6     Bovada     6.00         4  2006   \n",
       "\n",
       "   Month  Week  Weekday  \n",
       "0     11    44        2  \n",
       "1     11    44        2  \n",
       "2     11    44        2  \n",
       "3     11    44        2  \n",
       "4     11    44        2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Week'] = df['Date'].dt.week\n",
    "df['Weekday'] = df['Date'].dt.dayofweek\n",
    "df = df.sort_values(by=['Date'])\n",
    "df = df.reset_index()\n",
    "df = df.drop(['index','Date'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>HTWin</th>\n",
       "      <th>HTLoss</th>\n",
       "      <th>HT%</th>\n",
       "      <th>ATWin</th>\n",
       "      <th>ATLoss</th>\n",
       "      <th>AT%</th>\n",
       "      <th>TopLine</th>\n",
       "      <th>TLCompany</th>\n",
       "      <th>BotLine</th>\n",
       "      <th>BLCompany</th>\n",
       "      <th>NumComps</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>average</th>\n",
       "      <th>WinMargin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>4.75</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>7.00</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>4.75</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>6.00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HomeTeam  AwayTeam  HTWin  HTLoss  HT%  ATWin  ATLoss  AT%  TopLine  \\\n",
       "0         0        27    1.0     0.0  1.0    0.0     1.0  0.0        5   \n",
       "1         1        14    1.0     0.0  1.0    0.0     1.0  0.0        7   \n",
       "2         2        23    0.0     1.0  0.0    1.0     0.0  1.0        5   \n",
       "3         3        17    1.0     0.0  1.0    1.0     1.0  0.5       -1   \n",
       "4         4        21    1.0     0.0  1.0    0.0     1.0  0.0        6   \n",
       "\n",
       "   TLCompany  BotLine  BLCompany  NumComps  Year  Month  Week  Weekday  \\\n",
       "0          0        4          1         4  2006     11    44        2   \n",
       "1          1        7          1         4  2006     11    44        2   \n",
       "2          2        4          3         4  2006     11    44        2   \n",
       "3          1       -2          2         4  2006     11    44        2   \n",
       "4          2        6          2         4  2006     11    44        2   \n",
       "\n",
       "   average  WinMargin  \n",
       "0     4.75          9  \n",
       "1     7.00         10  \n",
       "2     4.75         -1  \n",
       "3    -1.25         15  \n",
       "4     6.00          3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['average'] = df['Average']\n",
    "df = df.drop(['Average'], axis=1)\n",
    "cols_at_end = ['WinMargin']\n",
    "df = df[[c for c in df if c not in cols_at_end] + [c for c in cols_at_end if c in df]]\n",
    "team = df.HomeTeam.unique()\n",
    "team_dict = dict(zip(team, range(len(team))))\n",
    "df1 = df.copy(deep=True)\n",
    "df1 = df1.replace({'HomeTeam': team_dict})\n",
    "df1 = df1.replace({'AwayTeam': team_dict})\n",
    "better = df1.TLCompany.unique()\n",
    "bet_dict = dict(zip(better, range(len(better))))\n",
    "df1 = df1.replace({'TLCompany': bet_dict})\n",
    "df1 = df1.replace({'BLCompany': bet_dict})\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>HTWin</th>\n",
       "      <th>HTLoss</th>\n",
       "      <th>HT%</th>\n",
       "      <th>ATWin</th>\n",
       "      <th>ATLoss</th>\n",
       "      <th>AT%</th>\n",
       "      <th>TopLine</th>\n",
       "      <th>TLCompany</th>\n",
       "      <th>BotLine</th>\n",
       "      <th>BLCompany</th>\n",
       "      <th>NumComps</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>average</th>\n",
       "      <th>WinMargin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>4.75</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>7.00</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>4.75</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>6.00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HomeTeam  AwayTeam  HTWin  HTLoss  HT%  ATWin  ATLoss  AT%  TopLine  \\\n",
       "0         0        27    0.0     0.0  NaN    0.0     0.0  NaN        5   \n",
       "1         1        14    0.0     0.0  NaN    0.0     0.0  NaN        7   \n",
       "2         2        23    0.0     0.0  NaN    0.0     0.0  NaN        5   \n",
       "3         3        17    0.0     0.0  NaN    1.0     0.0  1.0       -1   \n",
       "4         4        21    0.0     0.0  NaN    0.0     0.0  NaN        6   \n",
       "\n",
       "   TLCompany  BotLine  BLCompany  NumComps  Year  Month  Week  Weekday  \\\n",
       "0          0        4          1         4  2006     11    44        2   \n",
       "1          1        7          1         4  2006     11    44        2   \n",
       "2          2        4          3         4  2006     11    44        2   \n",
       "3          1       -2          2         4  2006     11    44        2   \n",
       "4          2        6          2         4  2006     11    44        2   \n",
       "\n",
       "   average  WinMargin  \n",
       "0     4.75          9  \n",
       "1     7.00         10  \n",
       "2     4.75         -1  \n",
       "3    -1.25         15  \n",
       "4     6.00          3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df1.copy(deep=True)\n",
    "df2.loc[df2['WinMargin'] < 0, 'HTLoss'] = df2['HTLoss']-1\n",
    "df2.loc[df2['WinMargin'] >= 0, 'HTWin'] = df2['HTWin']-1\n",
    "df2.loc[df2['WinMargin'] < 0, 'ATWin'] = df2['ATWin']-1\n",
    "df2.loc[df2['WinMargin'] >= 0, 'ATLoss'] = df2['ATLoss']-1\n",
    "df2['HT%'] = df2['HTWin']/(df2['HTWin'] + df2['HTLoss'])\n",
    "df2['AT%'] = df2['ATWin']/(df2['ATWin'] + df2['ATLoss'])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[df2['WinMargin'] > df2['average'], 'Over'] = 1\n",
    "df2.loc[df2['WinMargin'] <= df2['average'], 'Over'] = 0\n",
    "df2 = df2.drop(['WinMargin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "cols = df2.columns.values\n",
    "cols = np.delete(cols,np.where(cols=='Over'))\n",
    "df2 = df2.reset_index()\n",
    "df2 = df2.drop(['index'], axis=1)\n",
    "df2 = df2.fillna(0)\n",
    "sc2 = StandardScaler()\n",
    "for col in cols:\n",
    "    df2[[col]] = sc2.fit_transform(df2[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df2[0:(round(len(df2)*.8))] \n",
    "test=df2[(round(len(df2)*.8)):]\n",
    "trains = np.split(train, [18], axis=1)\n",
    "train_x=trains[0]\n",
    "train_y=trains[1]\n",
    "tests = np.split(test, [18], axis=1)\n",
    "test_x=tests[0]\n",
    "test_y=tests[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_r2_score(r2, n, k):\n",
    "    return 1-((1-r2)*((n-1)/(n-k-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14898</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14899</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14900</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14901</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14902</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Over\n",
       "14898   0.0\n",
       "14899   0.0\n",
       "14900   1.0\n",
       "14901   0.0\n",
       "14902   0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train accuracy is 61.155846334507636\n",
      "The test accuracy is 50.754780275075476\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "model = tree.DecisionTreeClassifier(max_depth=10)\n",
    "model.fit(train_x.values, train_y.values)\n",
    "y_pred = model.predict(test_x.values)\n",
    "y_pred2 = model.predict(train_x.values)\n",
    "trainaccuracy =  accuracy_score(train_y.values, y_pred2) * 100\n",
    "testaccuracy =  accuracy_score(test_y.values, y_pred) * 100\n",
    "print('The train accuracy is ' + str(trainaccuracy))\n",
    "print('The test accuracy is ' + str(testaccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train accuracy is 83.93725884918638\n",
      "The test accuracy is 50.55350553505535\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model2 = RandomForestClassifier(n_estimators=100, )\n",
    "model2.fit(train_x.values, train_y.values)\n",
    "y_pred = model2.predict(test_x.values)\n",
    "y_pred2 = model2.predict(train_x.values)\n",
    "trainaccuracy =  accuracy_score(train_y.values, y_pred2) * 100\n",
    "testaccuracy =  accuracy_score(test_y.values, y_pred) * 100\n",
    "print('The train accuracy is ' + str(trainaccuracy))\n",
    "print('The test accuracy is ' + str(testaccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train accuracy is 100.0\n",
      "The test accuracy is 50.788326065078834\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "model3 = ExtraTreesClassifier(n_estimators=100, bootstrap=True, )\n",
    "model3.fit(train_x.values, train_y.values)\n",
    "y_pred = model3.predict(test_x.values)\n",
    "y_pred2 = model3.predict(train_x.values)\n",
    "trainaccuracy =  accuracy_score(train_y.values, y_pred2) * 100\n",
    "testaccuracy =  accuracy_score(test_y.values, y_pred) * 100\n",
    "print('The train accuracy is ' + str(trainaccuracy))\n",
    "print('The test accuracy is ' + str(testaccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train accuracy is 57.15483979198122\n",
      "The test accuracy is 50.754780275075476\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model4 = XGBClassifier(n_jobs=5,n_estimators=100,gamma=0.1,learning_rate=0.04)\n",
    "model4.fit(train_x.values, train_y.values)\n",
    "y_pred = model4.predict(test_x.values)\n",
    "y_pred2 = model4.predict(train_x.values)\n",
    "trainaccuracy =  accuracy_score(train_y.values, y_pred2) * 100\n",
    "testaccuracy =  accuracy_score(test_y.values, y_pred) * 100\n",
    "print('The train accuracy is ' + str(trainaccuracy))\n",
    "print('The test accuracy is ' + str(testaccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train accuracy is 68.54554604932058\n",
      "The test accuracy is 50.318685005031874\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "model6 = neighbors.KNeighborsClassifier()\n",
    "model6.fit(train_x.values, train_y.values)\n",
    "y_pred = model6.predict(test_x.values)\n",
    "y_pred2 = model6.predict(train_x.values)\n",
    "trainaccuracy =  accuracy_score(train_y.values, y_pred2) * 100\n",
    "testaccuracy =  accuracy_score(test_y.values, y_pred) * 100\n",
    "print('The train accuracy is ' + str(trainaccuracy))\n",
    "print('The test accuracy is ' + str(testaccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "30.20144271666667 minutes have elapsed. TPOT will close down.\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "Best pipeline: LogisticRegression(LogisticRegression(GaussianNB(ZeroCount(GaussianNB(Binarizer(input_matrix, threshold=0.55)))), C=0.5, dual=False, penalty=l1), C=1.0, dual=False, penalty=l1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict='TPOT light', crossover_rate=0.1, cv=5,\n",
       "        disable_update_check=False, early_stop=None, generations=1000000,\n",
       "        max_eval_time_mins=5, max_time_mins=30, memory=None,\n",
       "        mutation_rate=0.9, n_jobs=1, offspring_size=None,\n",
       "        periodic_checkpoint_folder=None, population_size=10,\n",
       "        random_state=None, scoring=None, subsample=1.0,\n",
       "        template='RandomTree', use_dask=False, verbosity=1,\n",
       "        warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "\n",
    "#my_custom_scorer = make_scorer(my_custom_accuracy, greater_is_better=True)\n",
    "\n",
    "tpot = TPOTClassifier(population_size=10, max_time_mins=30, verbosity=1, config_dict='TPOT light')\n",
    "tpot.fit(train_x.values, train_y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train accuracy is 52.68411340379131\n",
      "The test accuracy is 49.91613552499161\n"
     ]
    }
   ],
   "source": [
    "y_pred = tpot.predict(test_x.values)\n",
    "y_pred2 = tpot.predict(train_x.values)\n",
    "trainaccuracy =  accuracy_score(train_y.values, y_pred2) * 100\n",
    "testaccuracy =  accuracy_score(test_y.values, y_pred) * 100\n",
    "print('The train accuracy is ' + str(trainaccuracy))\n",
    "print('The test accuracy is ' + str(testaccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.layers import LSTM\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11922 samples, validate on 2981 samples\n",
      "Epoch 1/100\n",
      "11922/11922 [==============================] - 2s 167us/step - loss: 0.8816 - acc: 0.5122 - val_loss: 0.7319 - val_acc: 0.4901\n",
      "Epoch 2/100\n",
      "11922/11922 [==============================] - 1s 77us/step - loss: 0.7100 - acc: 0.5055 - val_loss: 0.6985 - val_acc: 0.4988\n",
      "Epoch 3/100\n",
      "11922/11922 [==============================] - 1s 73us/step - loss: 0.6959 - acc: 0.4976 - val_loss: 0.6944 - val_acc: 0.4951\n",
      "Epoch 4/100\n",
      "11922/11922 [==============================] - 1s 73us/step - loss: 0.6944 - acc: 0.4978 - val_loss: 0.6939 - val_acc: 0.4951\n",
      "Epoch 5/100\n",
      "11922/11922 [==============================] - 1s 73us/step - loss: 0.6942 - acc: 0.5033 - val_loss: 0.6941 - val_acc: 0.4951\n",
      "Epoch 6/100\n",
      "11922/11922 [==============================] - 1s 73us/step - loss: 0.6943 - acc: 0.5071 - val_loss: 0.6941 - val_acc: 0.4951\n",
      "Epoch 7/100\n",
      "11922/11922 [==============================] - 1s 75us/step - loss: 0.6942 - acc: 0.5065 - val_loss: 0.6940 - val_acc: 0.4951\n",
      "Epoch 8/100\n",
      "11922/11922 [==============================] - 1s 72us/step - loss: 0.6943 - acc: 0.5073 - val_loss: 0.6941 - val_acc: 0.4951\n",
      "Epoch 9/100\n",
      "11922/11922 [==============================] - 1s 73us/step - loss: 0.6944 - acc: 0.5078 - val_loss: 0.6941 - val_acc: 0.4951\n",
      "Epoch 10/100\n",
      "11922/11922 [==============================] - 1s 73us/step - loss: 0.6944 - acc: 0.5065 - val_loss: 0.6943 - val_acc: 0.4951\n",
      "Epoch 11/100\n",
      "11922/11922 [==============================] - 1s 73us/step - loss: 0.6944 - acc: 0.5055 - val_loss: 0.6941 - val_acc: 0.4951\n",
      "Epoch 12/100\n",
      "11922/11922 [==============================] - 1s 77us/step - loss: 0.6946 - acc: 0.5067 - val_loss: 0.6944 - val_acc: 0.4951\n",
      "Epoch 13/100\n",
      "11922/11922 [==============================] - 1s 78us/step - loss: 0.6948 - acc: 0.5054 - val_loss: 0.6961 - val_acc: 0.4938\n",
      "Epoch 14/100\n",
      "11922/11922 [==============================] - 1s 81us/step - loss: 0.6946 - acc: 0.5050 - val_loss: 0.6955 - val_acc: 0.4948\n",
      "Epoch 15/100\n",
      "11922/11922 [==============================] - 1s 104us/step - loss: 0.6949 - acc: 0.5075 - val_loss: 0.6959 - val_acc: 0.4938\n",
      "Epoch 16/100\n",
      "11922/11922 [==============================] - 1s 76us/step - loss: 0.6949 - acc: 0.5070 - val_loss: 0.6948 - val_acc: 0.4948\n",
      "Epoch 17/100\n",
      "11922/11922 [==============================] - 1s 96us/step - loss: 0.6949 - acc: 0.5051 - val_loss: 0.6946 - val_acc: 0.4958\n",
      "Epoch 18/100\n",
      "11922/11922 [==============================] - 1s 80us/step - loss: 0.6947 - acc: 0.5063 - val_loss: 0.6955 - val_acc: 0.4918\n",
      "Epoch 19/100\n",
      "11922/11922 [==============================] - 1s 75us/step - loss: 0.6948 - acc: 0.5065 - val_loss: 0.6949 - val_acc: 0.4945\n",
      "Epoch 20/100\n",
      "11922/11922 [==============================] - 1s 76us/step - loss: 0.6949 - acc: 0.5057 - val_loss: 0.6960 - val_acc: 0.4941\n",
      "Epoch 21/100\n",
      "11922/11922 [==============================] - 1s 78us/step - loss: 0.6949 - acc: 0.5044 - val_loss: 0.6938 - val_acc: 0.4955\n",
      "Epoch 22/100\n",
      "11922/11922 [==============================] - 1s 76us/step - loss: 0.6949 - acc: 0.5040 - val_loss: 0.6942 - val_acc: 0.4951\n",
      "Epoch 23/100\n",
      "11922/11922 [==============================] - 1s 82us/step - loss: 0.6950 - acc: 0.5041 - val_loss: 0.6956 - val_acc: 0.4948\n",
      "Epoch 24/100\n",
      "11922/11922 [==============================] - 1s 84us/step - loss: 0.6946 - acc: 0.5060 - val_loss: 0.6962 - val_acc: 0.4935\n",
      "Epoch 25/100\n",
      "11922/11922 [==============================] - 1s 91us/step - loss: 0.6947 - acc: 0.5023 - val_loss: 0.6950 - val_acc: 0.4948\n",
      "Epoch 26/100\n",
      "11922/11922 [==============================] - 1s 85us/step - loss: 0.6946 - acc: 0.5050 - val_loss: 0.6941 - val_acc: 0.4948\n",
      "Epoch 27/100\n",
      "11922/11922 [==============================] - 1s 77us/step - loss: 0.6948 - acc: 0.5057 - val_loss: 0.6944 - val_acc: 0.4951\n",
      "Epoch 28/100\n",
      "11922/11922 [==============================] - 1s 79us/step - loss: 0.6946 - acc: 0.5061 - val_loss: 0.6943 - val_acc: 0.4951\n",
      "Epoch 29/100\n",
      "11922/11922 [==============================] - 1s 75us/step - loss: 0.6948 - acc: 0.5055 - val_loss: 0.6942 - val_acc: 0.4948\n",
      "Epoch 30/100\n",
      "11922/11922 [==============================] - 1s 77us/step - loss: 0.6946 - acc: 0.5078 - val_loss: 0.6955 - val_acc: 0.4928\n",
      "Epoch 31/100\n",
      "11922/11922 [==============================] - 1s 74us/step - loss: 0.6946 - acc: 0.5041 - val_loss: 0.6952 - val_acc: 0.4945\n",
      "Epoch 32/100\n",
      "11922/11922 [==============================] - 1s 82us/step - loss: 0.6946 - acc: 0.5065 - val_loss: 0.6958 - val_acc: 0.4938\n",
      "Epoch 33/100\n",
      "11922/11922 [==============================] - 1s 92us/step - loss: 0.6946 - acc: 0.5030 - val_loss: 0.6955 - val_acc: 0.4918\n",
      "Epoch 34/100\n",
      "11922/11922 [==============================] - 1s 81us/step - loss: 0.6946 - acc: 0.5077 - val_loss: 0.6949 - val_acc: 0.4941\n",
      "Epoch 35/100\n",
      "11922/11922 [==============================] - 1s 80us/step - loss: 0.6946 - acc: 0.5055 - val_loss: 0.6956 - val_acc: 0.4958\n",
      "Epoch 36/100\n",
      "11922/11922 [==============================] - 1s 96us/step - loss: 0.6946 - acc: 0.5036 - val_loss: 0.6954 - val_acc: 0.4935\n",
      "Epoch 37/100\n",
      "11922/11922 [==============================] - 1s 99us/step - loss: 0.6946 - acc: 0.5041 - val_loss: 0.6955 - val_acc: 0.4941\n",
      "Epoch 38/100\n",
      "11922/11922 [==============================] - 1s 90us/step - loss: 0.6946 - acc: 0.5049 - val_loss: 0.6947 - val_acc: 0.4948\n",
      "Epoch 39/100\n",
      "11922/11922 [==============================] - 1s 77us/step - loss: 0.6945 - acc: 0.5055 - val_loss: 0.6946 - val_acc: 0.4938\n",
      "Epoch 40/100\n",
      "11922/11922 [==============================] - 1s 85us/step - loss: 0.6945 - acc: 0.5062 - val_loss: 0.6950 - val_acc: 0.4955\n",
      "Epoch 41/100\n",
      "11922/11922 [==============================] - 1s 75us/step - loss: 0.6944 - acc: 0.5034 - val_loss: 0.6946 - val_acc: 0.4928\n",
      "Epoch 42/100\n",
      "11922/11922 [==============================] - 1s 85us/step - loss: 0.6944 - acc: 0.5057 - val_loss: 0.6953 - val_acc: 0.4941\n",
      "Epoch 43/100\n",
      "11922/11922 [==============================] - 1s 79us/step - loss: 0.6943 - acc: 0.5070 - val_loss: 0.6955 - val_acc: 0.4941\n",
      "Epoch 44/100\n",
      "11922/11922 [==============================] - 1s 86us/step - loss: 0.6945 - acc: 0.5035 - val_loss: 0.6949 - val_acc: 0.4935\n",
      "Epoch 45/100\n",
      "11922/11922 [==============================] - 1s 96us/step - loss: 0.6945 - acc: 0.5049 - val_loss: 0.6947 - val_acc: 0.4921\n",
      "Epoch 46/100\n",
      "11922/11922 [==============================] - 1s 77us/step - loss: 0.6945 - acc: 0.5052 - val_loss: 0.6944 - val_acc: 0.4938\n",
      "Epoch 47/100\n",
      "11922/11922 [==============================] - 1s 77us/step - loss: 0.6944 - acc: 0.5083 - val_loss: 0.6940 - val_acc: 0.4925\n",
      "Epoch 48/100\n",
      "11922/11922 [==============================] - 1s 74us/step - loss: 0.6944 - acc: 0.5074 - val_loss: 0.6938 - val_acc: 0.4938\n",
      "Epoch 49/100\n",
      "11922/11922 [==============================] - 1s 76us/step - loss: 0.6944 - acc: 0.5071 - val_loss: 0.6938 - val_acc: 0.4948\n",
      "Epoch 50/100\n",
      "11922/11922 [==============================] - 1s 73us/step - loss: 0.6943 - acc: 0.5074 - val_loss: 0.6938 - val_acc: 0.4935\n",
      "Epoch 51/100\n",
      "11922/11922 [==============================] - 1s 75us/step - loss: 0.6944 - acc: 0.5068 - val_loss: 0.6935 - val_acc: 0.4951\n",
      "Epoch 52/100\n",
      "11922/11922 [==============================] - 1s 73us/step - loss: 0.6943 - acc: 0.5076 - val_loss: 0.6938 - val_acc: 0.4941\n",
      "Epoch 53/100\n",
      "11922/11922 [==============================] - 1s 81us/step - loss: 0.6944 - acc: 0.5063 - val_loss: 0.6936 - val_acc: 0.4938\n",
      "Epoch 54/100\n",
      "11922/11922 [==============================] - 1s 74us/step - loss: 0.6942 - acc: 0.5061 - val_loss: 0.6935 - val_acc: 0.4951\n",
      "Epoch 55/100\n",
      "11922/11922 [==============================] - 1s 75us/step - loss: 0.6943 - acc: 0.5074 - val_loss: 0.6938 - val_acc: 0.4948\n",
      "Epoch 56/100\n",
      "11922/11922 [==============================] - 1s 74us/step - loss: 0.6944 - acc: 0.5057 - val_loss: 0.6938 - val_acc: 0.4938\n",
      "Epoch 57/100\n",
      "11922/11922 [==============================] - 1s 75us/step - loss: 0.6944 - acc: 0.5052 - val_loss: 0.6938 - val_acc: 0.4931\n",
      "Epoch 58/100\n",
      "11922/11922 [==============================] - 1s 85us/step - loss: 0.6944 - acc: 0.5065 - val_loss: 0.6936 - val_acc: 0.4938\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11922/11922 [==============================] - 1s 91us/step - loss: 0.6943 - acc: 0.5048 - val_loss: 0.6936 - val_acc: 0.4928\n",
      "Epoch 60/100\n",
      "11922/11922 [==============================] - 1s 72us/step - loss: 0.6943 - acc: 0.5055 - val_loss: 0.6935 - val_acc: 0.4931\n",
      "Epoch 61/100\n",
      "11922/11922 [==============================] - 1s 76us/step - loss: 0.6942 - acc: 0.5069 - val_loss: 0.6935 - val_acc: 0.4935\n",
      "Epoch 62/100\n",
      "11922/11922 [==============================] - 1s 77us/step - loss: 0.6943 - acc: 0.5062 - val_loss: 0.6934 - val_acc: 0.4948\n",
      "Epoch 63/100\n",
      "11922/11922 [==============================] - 1s 76us/step - loss: 0.6942 - acc: 0.5084 - val_loss: 0.6935 - val_acc: 0.4938\n",
      "Epoch 64/100\n",
      "11922/11922 [==============================] - 1s 75us/step - loss: 0.6942 - acc: 0.5056 - val_loss: 0.6935 - val_acc: 0.4931\n",
      "Epoch 65/100\n",
      "11922/11922 [==============================] - 1s 76us/step - loss: 0.6943 - acc: 0.5085 - val_loss: 0.6936 - val_acc: 0.4938\n",
      "Epoch 66/100\n",
      "11922/11922 [==============================] - 1s 77us/step - loss: 0.6943 - acc: 0.5078 - val_loss: 0.6935 - val_acc: 0.4925\n",
      "Epoch 67/100\n",
      "11922/11922 [==============================] - 1s 73us/step - loss: 0.6942 - acc: 0.5081 - val_loss: 0.6935 - val_acc: 0.4925\n",
      "Epoch 68/100\n",
      "11922/11922 [==============================] - 1s 77us/step - loss: 0.6942 - acc: 0.5078 - val_loss: 0.6936 - val_acc: 0.4918\n",
      "Epoch 69/100\n",
      "11922/11922 [==============================] - 1s 87us/step - loss: 0.6942 - acc: 0.5102 - val_loss: 0.6937 - val_acc: 0.4938\n",
      "Epoch 70/100\n",
      "11922/11922 [==============================] - 1s 75us/step - loss: 0.6943 - acc: 0.5076 - val_loss: 0.6937 - val_acc: 0.4935\n",
      "Epoch 71/100\n",
      "11922/11922 [==============================] - 1s 82us/step - loss: 0.6943 - acc: 0.5076 - val_loss: 0.6936 - val_acc: 0.4931\n",
      "Epoch 72/100\n",
      "11922/11922 [==============================] - 1s 80us/step - loss: 0.6942 - acc: 0.5108 - val_loss: 0.6936 - val_acc: 0.4938\n",
      "Epoch 73/100\n",
      "11922/11922 [==============================] - 1s 74us/step - loss: 0.6942 - acc: 0.5106 - val_loss: 0.6936 - val_acc: 0.4941\n",
      "Epoch 74/100\n",
      "11922/11922 [==============================] - 1s 72us/step - loss: 0.6941 - acc: 0.5112 - val_loss: 0.6936 - val_acc: 0.4938\n",
      "Epoch 75/100\n",
      "11922/11922 [==============================] - 1s 76us/step - loss: 0.6942 - acc: 0.5101 - val_loss: 0.6936 - val_acc: 0.4931\n",
      "Epoch 76/100\n",
      "11922/11922 [==============================] - 1s 75us/step - loss: 0.6942 - acc: 0.5091 - val_loss: 0.6938 - val_acc: 0.4948\n",
      "Epoch 77/100\n",
      "11922/11922 [==============================] - 1s 78us/step - loss: 0.6943 - acc: 0.5088 - val_loss: 0.6938 - val_acc: 0.4948\n",
      "Epoch 78/100\n",
      "11922/11922 [==============================] - 1s 70us/step - loss: 0.6943 - acc: 0.5091 - val_loss: 0.6937 - val_acc: 0.4931\n",
      "Epoch 79/100\n",
      "11922/11922 [==============================] - 1s 81us/step - loss: 0.6941 - acc: 0.5104 - val_loss: 0.6937 - val_acc: 0.4938\n",
      "Epoch 80/100\n",
      "11922/11922 [==============================] - 1s 83us/step - loss: 0.6942 - acc: 0.5099 - val_loss: 0.6937 - val_acc: 0.4911\n",
      "Epoch 81/100\n",
      "11922/11922 [==============================] - 1s 72us/step - loss: 0.6942 - acc: 0.5085 - val_loss: 0.6936 - val_acc: 0.4955\n",
      "Epoch 82/100\n",
      "11922/11922 [==============================] - 1s 74us/step - loss: 0.6941 - acc: 0.5097 - val_loss: 0.6937 - val_acc: 0.4945\n",
      "Epoch 83/100\n",
      "11922/11922 [==============================] - 1s 73us/step - loss: 0.6942 - acc: 0.5096 - val_loss: 0.6938 - val_acc: 0.4945\n",
      "Epoch 84/100\n",
      "11922/11922 [==============================] - 1s 73us/step - loss: 0.6942 - acc: 0.5096 - val_loss: 0.6937 - val_acc: 0.4928\n",
      "Epoch 85/100\n",
      "11922/11922 [==============================] - 1s 74us/step - loss: 0.6941 - acc: 0.5106 - val_loss: 0.6936 - val_acc: 0.4935\n",
      "Epoch 86/100\n",
      "11922/11922 [==============================] - 1s 74us/step - loss: 0.6941 - acc: 0.5092 - val_loss: 0.6937 - val_acc: 0.4931\n",
      "Epoch 87/100\n",
      "11922/11922 [==============================] - 1s 80us/step - loss: 0.6942 - acc: 0.5092 - val_loss: 0.6938 - val_acc: 0.4951\n",
      "Epoch 88/100\n",
      "11922/11922 [==============================] - 1s 78us/step - loss: 0.6941 - acc: 0.5078 - val_loss: 0.6937 - val_acc: 0.4931\n",
      "Epoch 89/100\n",
      "11922/11922 [==============================] - 1s 73us/step - loss: 0.6941 - acc: 0.5091 - val_loss: 0.6937 - val_acc: 0.4965\n",
      "Epoch 90/100\n",
      "11922/11922 [==============================] - 1s 74us/step - loss: 0.6941 - acc: 0.5087 - val_loss: 0.6938 - val_acc: 0.4958\n",
      "Epoch 91/100\n",
      "11922/11922 [==============================] - 1s 75us/step - loss: 0.6941 - acc: 0.5087 - val_loss: 0.6937 - val_acc: 0.4955\n",
      "Epoch 92/100\n",
      "11922/11922 [==============================] - 1s 74us/step - loss: 0.6941 - acc: 0.5093 - val_loss: 0.6937 - val_acc: 0.4951\n",
      "Epoch 93/100\n",
      "11922/11922 [==============================] - 1s 71us/step - loss: 0.6940 - acc: 0.5090 - val_loss: 0.6936 - val_acc: 0.4955\n",
      "Epoch 94/100\n",
      "11922/11922 [==============================] - 1s 73us/step - loss: 0.6940 - acc: 0.5107 - val_loss: 0.6937 - val_acc: 0.4945\n",
      "Epoch 95/100\n",
      "11922/11922 [==============================] - 1s 73us/step - loss: 0.6940 - acc: 0.5092 - val_loss: 0.6938 - val_acc: 0.4901\n",
      "Epoch 96/100\n",
      "11922/11922 [==============================] - 1s 88us/step - loss: 0.6940 - acc: 0.5096 - val_loss: 0.6938 - val_acc: 0.4925\n",
      "Epoch 97/100\n",
      "11922/11922 [==============================] - 1s 90us/step - loss: 0.6940 - acc: 0.5094 - val_loss: 0.6937 - val_acc: 0.4961\n",
      "Epoch 98/100\n",
      "11922/11922 [==============================] - 1s 89us/step - loss: 0.6940 - acc: 0.5101 - val_loss: 0.6937 - val_acc: 0.4901\n",
      "Epoch 99/100\n",
      "11922/11922 [==============================] - 1s 86us/step - loss: 0.6940 - acc: 0.5100 - val_loss: 0.6937 - val_acc: 0.4921\n",
      "Epoch 100/100\n",
      "11922/11922 [==============================] - 1s 88us/step - loss: 0.6940 - acc: 0.5100 - val_loss: 0.6937 - val_acc: 0.4945\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=18, activation='tanh', kernel_initializer='random_normal', kernel_regularizer=regularizers.l2(0.13)))\n",
    "Dropout(.2)\n",
    "model.add(Dense(34, activation='tanh',kernel_initializer='random_normal', kernel_regularizer=regularizers.l2(0.03)))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics =['accuracy'])\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=0, min_delta=.000001,restore_best_weights=True)\n",
    "        \n",
    "out = model.fit(train_x.values, train_y.Over.values.ravel(), validation_data=[test_x.values, test_y['Over'].values.ravel()], epochs=100,verbose=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train accuracy is 50.04193927193425\n",
      "The test accuracy is 49.44649446494465\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.rint(model.predict(test_x.values))\n",
    "y_pred2 = np.rint(model.predict(train_x.values))\n",
    "trainaccuracy =  accuracy_score(train_y.values, y_pred2) * 100\n",
    "testaccuracy =  accuracy_score(test_y.values, y_pred) * 100\n",
    "print('The train accuracy is ' + str(trainaccuracy))\n",
    "print('The test accuracy is ' + str(testaccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
